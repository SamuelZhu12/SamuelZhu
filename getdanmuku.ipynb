{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaidBycid(cid):\n",
    "    temp = pd.read_csv('videoInfo.csv')\n",
    "    id = temp[temp['cid'] == cid]\n",
    "    return id.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRequest(url):\n",
    "        proxyHost = \"u5235.b5.t.16yun.cn\"\n",
    "        proxyPort = \"6460\"\n",
    "\n",
    "        # 代理验证信息\n",
    "        proxyUser = \"16SEDZVO\"\n",
    "        proxyPass = \"507049\"\n",
    "\n",
    "        proxyMeta = \"http://%(user)s:%(pass)s@%(host)s:%(port)s\" % {\n",
    "            \"host\" : proxyHost,\n",
    "            \"port\" : proxyPort,\n",
    "            \"user\" : proxyUser,\n",
    "            \"pass\" : proxyPass,\n",
    "        }\n",
    "\n",
    "    # 设置 http和https访问都是用HTTP代理\n",
    "        proxies = {\n",
    "            \"http\"  : proxyMeta,\n",
    "            \"https\" : proxyMeta,\n",
    "        }\n",
    "\n",
    "\n",
    "    #  设置IP切换头\n",
    "        tunnel = random.randint(1,10000)\n",
    "        user_agent=['Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET4.0C; .NET4.0E; 360SE)',\n",
    "'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729)',\n",
    "'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; QQBrowser/6.12)',\n",
    "'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0; Touch; MAARJS)'\n",
    "                   ]\n",
    "        headers = {\"Proxy-Tunnel\": str(tunnel),\n",
    "                  \"User-Agent\":choice(user_agent)}\n",
    "        try:\n",
    "#             time.sleep(random.random()*1.5)\n",
    "            r=requests.get(url,timeout = 30,proxies = proxies,headers = headers)\n",
    "            r.encoding = r.apparent_encoding\n",
    "            text = r.text\n",
    "            return text\n",
    "        except:\n",
    "            print('转换失败')\n",
    "            return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=None, index=None, columns=['aid','userId','comment'], dtype=None, copy=False)\n",
    "commentList={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取第1400条视频\n",
      "正在爬取第1401条视频\n",
      "正在爬取第1402条视频\n",
      "正在爬取第1403条视频\n",
      "正在爬取第1404条视频\n",
      "正在爬取第1405条视频\n",
      "正在爬取第1406条视频\n",
      "正在爬取第1407条视频\n",
      "正在爬取第1408条视频\n",
      "正在爬取第1409条视频\n",
      "正在爬取第1410条视频\n",
      "正在爬取第1411条视频\n",
      "正在爬取第1412条视频\n",
      "正在爬取第1413条视频\n",
      "正在爬取第1414条视频\n",
      "正在爬取第1415条视频\n",
      "正在爬取第1416条视频\n",
      "正在爬取第1417条视频\n",
      "正在爬取第1418条视频\n",
      "正在爬取第1419条视频\n",
      "正在爬取第1420条视频\n",
      "正在爬取第1421条视频\n",
      "正在爬取第1422条视频\n",
      "正在爬取第1423条视频\n",
      "正在爬取第1424条视频\n",
      "正在爬取第1425条视频\n",
      "正在爬取第1426条视频\n",
      "正在爬取第1427条视频\n",
      "正在爬取第1428条视频\n",
      "正在爬取第1429条视频\n",
      "正在爬取第1430条视频\n",
      "正在爬取第1431条视频\n",
      "正在爬取第1432条视频\n",
      "正在爬取第1433条视频\n",
      "正在爬取第1434条视频\n",
      "正在爬取第1435条视频\n",
      "正在爬取第1436条视频\n",
      "正在爬取第1437条视频\n",
      "正在爬取第1438条视频\n",
      "正在爬取第1439条视频\n",
      "正在爬取第1440条视频\n",
      "正在爬取第1441条视频\n",
      "正在爬取第1442条视频\n",
      "正在爬取第1443条视频\n",
      "正在爬取第1444条视频\n",
      "正在爬取第1445条视频\n",
      "正在爬取第1446条视频\n",
      "正在爬取第1447条视频\n",
      "正在爬取第1448条视频\n",
      "正在爬取第1449条视频\n",
      "正在爬取第1450条视频\n",
      "正在爬取第1451条视频\n",
      "正在爬取第1452条视频\n",
      "正在爬取第1453条视频\n",
      "正在爬取第1454条视频\n",
      "正在爬取第1455条视频\n",
      "正在爬取第1456条视频\n",
      "正在爬取第1457条视频\n",
      "正在爬取第1458条视频\n",
      "正在爬取第1459条视频\n",
      "正在爬取第1460条视频\n",
      "正在爬取第1461条视频\n",
      "正在爬取第1462条视频\n",
      "正在爬取第1463条视频\n",
      "正在爬取第1464条视频\n",
      "正在爬取第1465条视频\n",
      "正在爬取第1466条视频\n",
      "正在爬取第1467条视频\n",
      "正在爬取第1468条视频\n",
      "正在爬取第1469条视频\n",
      "正在爬取第1470条视频\n",
      "正在爬取第1471条视频\n",
      "正在爬取第1472条视频\n",
      "正在爬取第1473条视频\n",
      "正在爬取第1474条视频\n",
      "正在爬取第1475条视频\n",
      "正在爬取第1476条视频\n",
      "正在爬取第1477条视频\n",
      "正在爬取第1478条视频\n",
      "正在爬取第1479条视频\n",
      "正在爬取第1480条视频\n",
      "正在爬取第1481条视频\n",
      "正在爬取第1482条视频\n",
      "正在爬取第1483条视频\n",
      "正在爬取第1484条视频\n",
      "正在爬取第1485条视频\n",
      "正在爬取第1486条视频\n",
      "正在爬取第1487条视频\n",
      "正在爬取第1488条视频\n",
      "正在爬取第1489条视频\n",
      "正在爬取第1490条视频\n",
      "正在爬取第1491条视频\n",
      "正在爬取第1492条视频\n",
      "正在爬取第1493条视频\n",
      "正在爬取第1494条视频\n",
      "正在爬取第1495条视频\n",
      "正在爬取第1496条视频\n",
      "正在爬取第1497条视频\n",
      "正在爬取第1498条视频\n",
      "正在爬取第1499条视频\n",
      "正在爬取第1500条视频\n",
      "正在爬取第1501条视频\n",
      "正在爬取第1502条视频\n",
      "正在爬取第1503条视频\n",
      "正在爬取第1504条视频\n",
      "正在爬取第1505条视频\n",
      "正在爬取第1506条视频\n",
      "正在爬取第1507条视频\n",
      "正在爬取第1508条视频\n",
      "正在爬取第1509条视频\n",
      "正在爬取第1510条视频\n",
      "正在爬取第1511条视频\n",
      "正在爬取第1512条视频\n",
      "正在爬取第1513条视频\n",
      "正在爬取第1514条视频\n",
      "正在爬取第1515条视频\n",
      "正在爬取第1516条视频\n",
      "正在爬取第1517条视频\n",
      "正在爬取第1518条视频\n",
      "正在爬取第1519条视频\n",
      "正在爬取第1520条视频\n",
      "正在爬取第1521条视频\n",
      "正在爬取第1522条视频\n",
      "正在爬取第1523条视频\n",
      "正在爬取第1524条视频\n",
      "转换失败\n",
      "正在爬取第1525条视频\n",
      "正在爬取第1526条视频\n",
      "正在爬取第1527条视频\n",
      "正在爬取第1528条视频\n",
      "正在爬取第1529条视频\n",
      "正在爬取第1530条视频\n",
      "正在爬取第1531条视频\n",
      "正在爬取第1532条视频\n",
      "正在爬取第1533条视频\n",
      "正在爬取第1534条视频\n",
      "正在爬取第1535条视频\n",
      "正在爬取第1536条视频\n",
      "正在爬取第1537条视频\n",
      "正在爬取第1538条视频\n",
      "正在爬取第1539条视频\n",
      "正在爬取第1540条视频\n",
      "正在爬取第1541条视频\n",
      "正在爬取第1542条视频\n",
      "正在爬取第1543条视频\n",
      "正在爬取第1544条视频\n",
      "正在爬取第1545条视频\n",
      "正在爬取第1546条视频\n",
      "正在爬取第1547条视频\n",
      "正在爬取第1548条视频\n",
      "正在爬取第1549条视频\n",
      "正在爬取第1550条视频\n",
      "正在爬取第1551条视频\n",
      "正在爬取第1552条视频\n",
      "正在爬取第1553条视频\n",
      "正在爬取第1554条视频\n",
      "正在爬取第1555条视频\n",
      "转换失败\n",
      "正在爬取第1556条视频\n",
      "正在爬取第1557条视频\n",
      "正在爬取第1558条视频\n",
      "正在爬取第1559条视频\n",
      "正在爬取第1560条视频\n",
      "正在爬取第1561条视频\n",
      "正在爬取第1562条视频\n",
      "正在爬取第1563条视频\n",
      "正在爬取第1564条视频\n",
      "正在爬取第1565条视频\n",
      "正在爬取第1566条视频\n",
      "正在爬取第1567条视频\n",
      "正在爬取第1568条视频\n",
      "正在爬取第1569条视频\n",
      "正在爬取第1570条视频\n",
      "正在爬取第1571条视频\n",
      "正在爬取第1572条视频\n",
      "正在爬取第1573条视频\n",
      "正在爬取第1574条视频\n",
      "正在爬取第1575条视频\n",
      "正在爬取第1576条视频\n",
      "正在爬取第1577条视频\n",
      "正在爬取第1578条视频\n",
      "正在爬取第1579条视频\n",
      "正在爬取第1580条视频\n",
      "正在爬取第1581条视频\n",
      "正在爬取第1582条视频\n",
      "正在爬取第1583条视频\n",
      "正在爬取第1584条视频\n",
      "正在爬取第1585条视频\n",
      "正在爬取第1586条视频\n",
      "正在爬取第1587条视频\n",
      "正在爬取第1588条视频\n",
      "正在爬取第1589条视频\n",
      "正在爬取第1590条视频\n",
      "正在爬取第1591条视频\n",
      "正在爬取第1592条视频\n",
      "正在爬取第1593条视频\n",
      "正在爬取第1594条视频\n",
      "正在爬取第1595条视频\n",
      "正在爬取第1596条视频\n",
      "正在爬取第1597条视频\n",
      "正在爬取第1598条视频\n",
      "正在爬取第1599条视频\n",
      "program is over\n"
     ]
    }
   ],
   "source": [
    "dt = pd.read_csv(r'videoInfo.csv')\n",
    "cidlist = dt['cid']\n",
    "for i in range(1400,1600):\n",
    "    print('正在爬取第'+str(i)+'条视频')\n",
    "    aid = getaidBycid(cidlist[i])\n",
    "    url = 'https://comment.bilibili.com/'+str(cidlist[i])+'.xml'\n",
    "    ctext = getRequest(url)\n",
    "    soup = BeautifulSoup(ctext,\"html.parser\")\n",
    "    list = soup.find_all('d')\n",
    "    for comment in list:\n",
    "        userId = comment.attrs['p'].split(',')[6]\n",
    "        commentList[userId] = comment.string\n",
    "        newInfo =pd.DataFrame({'aid':aid,'userId':userId,'comment':comment.string},index=[0]) \n",
    "        df = df.append(newInfo,ignore_index=True)\n",
    "print('program is over')\n",
    "df.to_csv('danmuku8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=None, index=None, columns=['aid','userId','comment'], dtype=None, copy=False)\n",
    "commentList={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(r'videoInfo.csv')\n",
    "cidlist = dt['cid']\n",
    "for i in range(1000,1200):\n",
    "    print('正在爬取第'+str(i)+'条视频')\n",
    "    aid = getaidBycid(cidlist[i])\n",
    "    url = 'https://comment.bilibili.com/'+str(cidlist[i])+'.xml'\n",
    "    ctext = getRequest(url)\n",
    "    soup = BeautifulSoup(ctext,\"html.parser\")\n",
    "    list = soup.find_all('d')\n",
    "    for comment in list:\n",
    "        userId = comment.attrs['p'].split(',')[6]\n",
    "        commentList[userId] = comment.string\n",
    "        newInfo =pd.DataFrame({'aid':aid,'userId':userId,'comment':comment.string},index=[0]) \n",
    "        df = df.append(newInfo,ignore_index=True)\n",
    "print('program is over')\n",
    "df.to_csv('danmuku6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'\n",
    "            }\n",
    "url = 'https://comment.bilibili.com/209193714.xml'\n",
    "r = requests.get(url,timeout = 30,headers = headers)\n",
    "r.raise_for_status()\n",
    "r.encoding = r.apparent_encoding\n",
    "cText = r.text\n",
    "soup = BeautifulSoup(cText,\"html.parser\")\n",
    "list = soup.find_all('d')\n",
    "commentList={}\n",
    "df = pd.DataFrame(data=None, index=None, columns=['aid','userId','comment'], dtype=None, copy=False)\n",
    "for comment in list:\n",
    "    userId = comment.attrs['p'].split(',')[6]\n",
    "    commentList[userId] = comment.string\n",
    "    newInfo =pd.DataFrame({'aid':'a12312','userId':userId,'comment':comment.string},index=[0]) \n",
    "    df = df.append(newInfo,ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
